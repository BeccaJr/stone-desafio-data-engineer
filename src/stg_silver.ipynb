{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9caa2a07-5d9f-49b0-bb7b-e8dd19001f37",
   "metadata": {},
   "source": [
    "# Objetivo:\n",
    "\n",
    "- Recuperação dos dados das tabelas 'stg_empresas_bronze' e 'stg_socios_bronze';\n",
    "- Filtro de colunas;\n",
    "- Tipagem dos Dados;\n",
    "- Sanitização da Base;\n",
    "- Salvar saída das tabelas no banco de dados 'stg_empresas_silver' e 'stg_empresas_silver'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66feb336-3ec2-4a47-aed9-ea36552e15b7",
   "metadata": {},
   "source": [
    "### Import das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843da94-7590-4982-ac51-7d932456a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import psycopg2\n",
    "import gc\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from psycopg2 import sql\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcf767a-6073-439d-8c64-b3327440834e",
   "metadata": {},
   "source": [
    "### Definição dos Diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d498902-7780-4ce7-b4c7-e833b24b4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "\n",
    "SILVER_DIR = os.path.join(DATA_DIR, 'silver')\n",
    "\n",
    "# Garante que os diretórios existam\n",
    "os.makedirs(SILVER_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c401e1-5f1f-46d8-8450-1d6aa65ca5e4",
   "metadata": {},
   "source": [
    "### Ler as tabelas no Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da621e8-8fa7-4dfa-a66d-3aa0227ebd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega variáveis de ambiente (.env)\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASS = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c107772-403a-41b9-9164-14b3f33714f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexão com o PostgreSQL\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b7ae7-78f4-4726-89c3-731076ad61be",
   "metadata": {},
   "source": [
    "### Tabela Empresas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5945fa-4cc5-4d7e-9a8f-634867fdecaa",
   "metadata": {},
   "source": [
    "#### Leitura da Raw e Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be445cf-39c9-49c5-ab7b-07bdc7d36750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path para salvar o arquivo\n",
    "csv_empresas_temp = os.path.join(SILVER_DIR, \"silver_empresas_temp.csv\")\n",
    "\n",
    "# Se o arquivo já existir, remove antes de começar\n",
    "if os.path.exists(csv_empresas_temp):\n",
    "    os.remove(csv_empresas_temp)\n",
    "\n",
    "# --- Ler dados em chunks e salvar no CSV ---\n",
    "chunk_size = 500_000  # ajuste conforme memória disponível\n",
    "first_chunk = True\n",
    "\n",
    "with conn.cursor(name=\"server_side_cursor\") as cur:\n",
    "    # Server-side cursor para evitar carregar tudo na memória\n",
    "    cur.itersize = chunk_size\n",
    "    cur.execute(\"SELECT * FROM stg_empresas_bronze;\")\n",
    "    \n",
    "    for rows in iter(lambda: cur.fetchmany(chunk_size), []):\n",
    "        # Converte para Polars\n",
    "        df_chunk = pl.DataFrame(\n",
    "            rows,\n",
    "            schema=[desc[0] for desc in cur.description],\n",
    "            orient=\"row\"\n",
    "        )\n",
    "        \n",
    "        # --- TRATAMENTOS ---\n",
    "        df_chunk = df_chunk.select([\n",
    "            df_chunk.columns[0],\n",
    "            df_chunk.columns[1],\n",
    "            df_chunk.columns[2],\n",
    "            df_chunk.columns[3],\n",
    "            df_chunk.columns[4],\n",
    "            df_chunk.columns[5]\n",
    "        ]).rename({\n",
    "            df_chunk.columns[0]: \"cnpj\",\n",
    "            df_chunk.columns[1]: \"razao_social\",\n",
    "            df_chunk.columns[2]: \"natureza_juridica\",\n",
    "            df_chunk.columns[3]: \"qualificacao_responsavel\",\n",
    "            df_chunk.columns[4]: \"capital_social\",\n",
    "            df_chunk.columns[5]: \"cod_porte\"\n",
    "        })\n",
    "\n",
    "        # Conversão de tipos e limpeza\n",
    "        df_chunk = df_chunk.with_columns([\n",
    "            pl.col(\"natureza_juridica\").cast(pl.Int32, strict=False).fill_null(-1),\n",
    "            pl.col(\"qualificacao_responsavel\").cast(pl.Int32, strict=False).fill_null(-1),\n",
    "            pl.col(\"capital_social\").str.replace(\",\", \".\").cast(pl.Float64, strict=False).fill_null(0.0),\n",
    "            pl.col(\"cnpj\").cast(pl.Utf8),\n",
    "            pl.col(\"razao_social\").cast(pl.Utf8).str.strip_chars(),\n",
    "            pl.col(\"cod_porte\").cast(pl.Int32, strict=False).fill_null(-1)\n",
    "        ])\n",
    "\n",
    "        # Remove duplicatas dentro do chunk\n",
    "        df_chunk = df_chunk.unique()\n",
    "\n",
    "        # --- SALVAR CSV incremental ---\n",
    "        with open(csv_empresas_temp, \"a\" if not first_chunk else \"w\", encoding=\"utf-8\") as f:\n",
    "            df_chunk.write_csv(\n",
    "                file=f,\n",
    "                separator=\"~\",\n",
    "                include_header=first_chunk,\n",
    "                quote_style=\"necessary\"\n",
    "            )\n",
    "                \n",
    "        first_chunk = False\n",
    "\n",
    "        # --- LIBERAR MEMÓRIA ---\n",
    "        del df_chunk\n",
    "        gc.collect()\n",
    "\n",
    "print(\"CSV final limpo gerado no \", csv_empresas_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d8366-c8eb-4119-8234-e87d12a598dd",
   "metadata": {},
   "source": [
    "### Tabela Sócios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e5585-19e5-4d9c-90e3-ab39199ede93",
   "metadata": {},
   "source": [
    "#### Leitura Raw e Tratamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053bab3-96d3-45d0-b7b2-2b1c35d7f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path para salvar o arquivo\n",
    "csv_socios_temp = os.path.join(SILVER_DIR, \"silver_socios_temp.csv\")\n",
    "\n",
    "# Se o arquivo já existir, remove antes de começar\n",
    "if os.path.exists(csv_socios_temp):\n",
    "    os.remove(csv_socios_temp)\n",
    "\n",
    "# --- Ler dados em chunks e salvar no CSV ---\n",
    "chunk_size = 500_000  # ajuste conforme memória disponível\n",
    "first_chunk = True\n",
    "\n",
    "with conn.cursor(name=\"server_side_cursor\") as cur:\n",
    "    # Server-side cursor para evitar carregar tudo na memória\n",
    "    cur.itersize = chunk_size\n",
    "    cur.execute(\"SELECT * FROM stg_socios_bronze;\")\n",
    "    \n",
    "    for rows in iter(lambda: cur.fetchmany(chunk_size), []):\n",
    "        # Converte para Polars\n",
    "        df_chunk = pl.DataFrame(rows, schema=[desc[0] for desc in cur.description], orient=\"row\")\n",
    "        \n",
    "        # --- TRATAMENTOS ---\n",
    "        df_chunk = df_chunk.select([\n",
    "            df_chunk.columns[0],\n",
    "            df_chunk.columns[1],\n",
    "            df_chunk.columns[2],\n",
    "            df_chunk.columns[3],\n",
    "            df_chunk.columns[4]\n",
    "        ])\n",
    "        \n",
    "        df_chunk = df_chunk.rename({\n",
    "            df_chunk.columns[0]: \"cnpj\",\n",
    "            df_chunk.columns[1]: \"tipo_socio\",\n",
    "            df_chunk.columns[2]: \"nome_socio\",\n",
    "            df_chunk.columns[3]: \"documento_socio\",\n",
    "            df_chunk.columns[4]: \"codigo_qualificacao_socio\"\n",
    "        })\n",
    "\n",
    "        # Conversão de tipos\n",
    "        df_chunk = df_chunk.with_columns([\n",
    "            pl.col(\"tipo_socio\").cast(pl.Int32, strict=False).fill_null(-1),\n",
    "            pl.col(\"cnpj\").cast(pl.Utf8),\n",
    "            pl.col(\"nome_socio\").cast(pl.Utf8),\n",
    "            pl.col(\"documento_socio\").cast(pl.Utf8),\n",
    "            pl.col(\"codigo_qualificacao_socio\").cast(pl.Utf8)\n",
    "        ])\n",
    "        \n",
    "        # Limpeza de strings\n",
    "        df_chunk = df_chunk.with_columns([\n",
    "            pl.col(\"nome_socio\").str.strip_chars()\n",
    "        ])\n",
    "        \n",
    "        # Remove duplicatas\n",
    "        df_chunk = df_chunk.unique()\n",
    "        \n",
    "        # --- SALVAR CSV incremental ---\n",
    "        with open(csv_socios_temp, \"a\" if not first_chunk else \"w\", encoding=\"utf-8\") as f:\n",
    "            df_chunk.write_csv(\n",
    "                file=f,\n",
    "                separator=\"~\",\n",
    "                include_header=first_chunk,\n",
    "                quote_style=\"necessary\"\n",
    "            )\n",
    "                \n",
    "        first_chunk = False\n",
    "\n",
    "        # --- LIBERAR MEMÓRIA ---\n",
    "        del df_chunk\n",
    "        gc.collect()\n",
    "\n",
    "print(\"CSV final limpo gerado no \", csv_socios_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea6e2b-1239-4a41-af23-025d25fc5b20",
   "metadata": {},
   "source": [
    "### Salvar no Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db0ffd-f67d-44f6-9d94-6e03a11d056f",
   "metadata": {},
   "source": [
    "#### Mapeamento dos tipos do Polars para o Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66a367-4855-484d-99eb-f4c3c9b98bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferir_tipo_postgres(dtype: pl.datatypes.DataType) -> str:\n",
    "    if dtype == pl.Int64 or dtype == pl.Int32 or dtype == pl.UInt32 or dtype == pl.UInt64:\n",
    "        return \"BIGINT\"\n",
    "    elif dtype == pl.Float64 or dtype == pl.Float32:\n",
    "        return \"DOUBLE PRECISION\"\n",
    "    elif dtype == pl.Boolean:\n",
    "        return \"BOOLEAN\"\n",
    "    elif dtype == pl.Datetime or dtype == pl.Date:\n",
    "        return \"TIMESTAMP\"\n",
    "    else:\n",
    "        return \"TEXT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc89423-396f-415e-b421-fa0df70bb03d",
   "metadata": {},
   "source": [
    "#### Função escrever no banco de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c12c9-8314-4e7f-a84c-21f13d89e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escrever_banco(csv_temp, nome_tabela,\n",
    "                   dbname, user, password, host, port):\n",
    "    \n",
    "    # Lê apenas 1000 linhas para inferir o schema\n",
    "    df_sample = pl.read_csv(\n",
    "        csv_temp,\n",
    "        separator=\"~\",\n",
    "        encoding=\"utf-8\",\n",
    "        has_header=True,  # use True se seu CSV tem header\n",
    "        infer_schema_length=1000,\n",
    "        n_rows=1000,\n",
    "        truncate_ragged_lines=True,\n",
    "        ignore_errors=True\n",
    "    )\n",
    "\n",
    "    # Monta schema dinâmico\n",
    "    colunas = []\n",
    "    for col, dtype in zip(df_sample.columns, df_sample.dtypes):\n",
    "        pg_tipo = inferir_tipo_postgres(dtype)\n",
    "        colunas.append(f\"{col} {pg_tipo}\")\n",
    "\n",
    "    schema_sql = \",\\n    \".join(colunas)\n",
    "\n",
    "    # Conecta no Postgres\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=dbname,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        host=host,\n",
    "        port=port\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Cria tabela com nome dinâmico\n",
    "    cur.execute(sql.SQL(\"\"\"\n",
    "        DROP TABLE IF EXISTS {tabela};\n",
    "        CREATE TABLE {tabela} (\n",
    "            {schema}\n",
    "        );\n",
    "    \"\"\").format(\n",
    "        tabela=sql.Identifier(nome_tabela),\n",
    "        schema=sql.SQL(schema_sql)\n",
    "    ))\n",
    "\n",
    "    # COPY direto, sem abrir no Python\n",
    "    with open(csv_temp, \"r\", encoding=\"utf-8\") as f:\n",
    "        cur.copy_expert(\n",
    "            sql.SQL(\"COPY {tabela} FROM STDIN WITH CSV HEADER DELIMITER '~'\").format(\n",
    "                tabela=sql.Identifier(nome_tabela)\n",
    "            ),\n",
    "            f\n",
    "        )\n",
    "\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Tabela '{nome_tabela}' salva no Postgres via COPY\")\n",
    "\n",
    "    # Remove CSV temporário\n",
    "    if os.path.exists(csv_temp):\n",
    "        os.remove(csv_temp)\n",
    "        print(\"Arquivo temporário removido:\", csv_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1cc15-1800-4b5d-bf6f-3350a4914fb8",
   "metadata": {},
   "source": [
    "#### Chamar funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba98663-fadd-4e22-b0c8-9b26b79c7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_banco(\n",
    "    csv_temp=csv_empresas_temp,\n",
    "    nome_tabela=\"stg_empresas_silver\",\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558c8a2-cd56-49bf-ac9f-459aaf7760bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "escrever_banco(\n",
    "    csv_temp=csv_socios_temp,\n",
    "    nome_tabela=\"stg_socios_silver\",\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
