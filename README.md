# Stone Data Engineer Challenge

Este projeto tem como objetivo a construÃ§Ã£o de um **pipeline de ingestÃ£o, tratamento e persistÃªncia de dados do CNPJ (Empresas e SÃ³cios) da Receita Federal** em um banco de dados **PostgreSQL**, utilizando **Docker, Jupyter Lab e Polars**.

---

## ğŸ“‚ Estrutura de Pastas

```
â”œâ”€â”€ data/                # Armazena os arquivos em diferentes camadas (raw, bronze, silver, gold)
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â””â”€â”€ gold/
â”œâ”€â”€ src/                 # Notebooks de cada camada do pipeline
â”‚   â”œâ”€â”€ raw.ipynb
â”‚   â”œâ”€â”€ stg_bronze.ipynb
â”‚   â”œâ”€â”€ stg_silver.ipynb
â”‚   â””â”€â”€ stg_gold.ipynb
â”œâ”€â”€ .env.exemple         # Exemplo de configuraÃ§Ã£o de variÃ¡veis de ambiente
â”œâ”€â”€ docker-compose.yml   # ConfiguraÃ§Ã£o do ambiente Docker (Postgres + Jupyter Lab)
â”œâ”€â”€ requirements.txt     # DependÃªncias do projeto
â””â”€â”€ README.md
```

---

## âš™ï¸ PrÃ©-requisitos

- [Docker](https://docs.docker.com/get-docker/) instalado  
- [Docker Compose](https://docs.docker.com/compose/) instalado  

---

## ğŸš€ Como rodar o projeto

### 1. Clonar o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/seu-repo.git
cd seu-repo
```

### 2. Configurar variÃ¡veis de ambiente
Crie o arquivo `.env` na raiz do projeto (baseado no `.env.exemple`):

```env
DB_HOST=db
DB_PORT=5432
DB_NAME=stone
DB_USER=stone
DB_PASSWORD=stone
```

### 3. Subir os containers
```bash
docker-compose up -d
```

Isso irÃ¡ iniciar:
- **Postgres** na porta `5432`  
- **Jupyter Lab** na porta `8888`  

Acesse: [http://localhost:8888](http://localhost:8888)

---

## ğŸ“Š Pipeline de Dados

1. **Raw Layer (`raw.ipynb`)**  
   - Faz download dos arquivos de **Empresas** e **SÃ³cios** diretamente do site da Receita Federal  
   - Salva os `.zip` em `data/raw`  
   - Extrai os arquivos `.EMPRECSV` e `.SOCIOCSV`

2. **Bronze Layer (`stg_bronze.ipynb`)**  
   - LÃª os arquivos **Raw**  
   - Salva arquivos temporÃ¡rios em `data/bronze`  
   - Cria as tabelas no Postgres:  
     - `stg_empresas_bronze`  
     - `stg_socios_bronze`

3. **Silver Layer (`stg_silver.ipynb`)**  
   - LÃª dados das tabelas **Bronze**  
   - Realiza **limpeza, tipagem e seleÃ§Ã£o de colunas**  
   - Remove duplicatas e sanitiza campos  
   - Cria as tabelas no Postgres:  
     - `stg_empresas_silver`  
     - `stg_socios_silver`

4. **Gold Layer (`stg_gold.ipynb`)**  
   - Seleciona colunas de interesse:  
     - `cnpj` (string)  
     - `qtde_socios` (int)  
     - `flag_socio_estrangeiro` (boolean)  
     - `doc_alvo` (boolean)  
   - Cria tabela final no Postgres:  
     - `prd_empresas_socios_gold`

---

## ğŸ”„ Fluxo do Pipeline

```mermaid
flowchart LR
    A[Raw Layer] -->|Download arquivos Receita Federal| B[Bronze Layer]
    B -->|Limpeza inicial + staging| C[Silver Layer]
    C -->|TransformaÃ§Ãµes + padronizaÃ§Ã£o| D[Gold Layer]
    D -->|Tabela final consolidada| E[(Postgres)]
```

---

## ğŸ“¦ DependÃªncias

As dependÃªncias estÃ£o listadas em `requirements.txt`:

- pandas  
- polars  
- psycopg2-binary  
- sqlalchemy  
- requests  
- python-dotenv  
- tqdm  
- jupyterlab  

---

## ğŸ› ï¸ Comandos Ãºteis

- Ver logs do Postgres:
  ```bash
  docker logs stone_db
  ```

- Acessar Postgres via psql:
  ```bash
  docker exec -it stone_db psql -U stone -d stone
  ```

- Derrubar containers:
  ```bash
  docker-compose down
  ```

---

## ğŸ“Œ ObservaÃ§Ãµes

- Os arquivos da Receita Federal sÃ£o **grandes** â†’ recomenda-se rodar em mÃ¡quina com boa memÃ³ria RAM.  
- Caso queira apenas testar, utilize uma **amostra menor de dados** para validar o pipeline.  
